{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic - Classification Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. (Business) Goal:\n",
    "- Goal of this project is to be able to build a model which is able to predict the circumstances on which the passengers of the titanic survived or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get Data\n",
    "- I decided to get the data from seaborn to make sure other people can reproduce the same results on their device and herefore having access to the exact same dataset. The seaborn dataset looks mostly the same as the dataset given in the kaggle competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first taking a look at the first lines to make sure import worked as expected.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     891 non-null    int64   \n",
      " 1   pclass       891 non-null    int64   \n",
      " 2   sex          891 non-null    object  \n",
      " 3   age          714 non-null    float64 \n",
      " 4   sibsp        891 non-null    int64   \n",
      " 5   parch        891 non-null    int64   \n",
      " 6   fare         891 non-null    float64 \n",
      " 7   embarked     889 non-null    object  \n",
      " 8   class        891 non-null    category\n",
      " 9   who          891 non-null    object  \n",
      " 10  adult_male   891 non-null    bool    \n",
      " 11  deck         203 non-null    category\n",
      " 12  embark_town  889 non-null    object  \n",
      " 13  alive        891 non-null    object  \n",
      " 14  alone        891 non-null    bool    \n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The columns `deck` and `age` seem to have a lot of missing values. The rest seems to be fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived         0\n",
       "pclass           0\n",
       "sex              0\n",
       "age            177\n",
       "sibsp            0\n",
       "parch            0\n",
       "fare             0\n",
       "embarked         2\n",
       "class            0\n",
       "who              0\n",
       "adult_male       0\n",
       "deck           688\n",
       "embark_town      2\n",
       "alive            0\n",
       "alone            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train/Test split\n",
    "- Before I can split the dataset I want to make sure, that the data I pass makes sense. \n",
    "    - I have a lot of missing values in the `deck` column. I will drop this column as in imputation on this one may generate a lot of non-representant values.\n",
    "    - For the same reason I will drop the `age` column. Also we do have information in the `who` column regarding if adult or child. This may be enough information to derive from an attribute as `age`\n",
    "    - I will remove the `adult_male` column as it is only a filter for the `who` column returning `True` if it is a man.\n",
    "    - The column `pclass` will also be removed, as we have the same information in the `class` column.\n",
    "    - I will also drop the `alive` column as this is only a resemblance of the `survived` column. I will use the `survived` column as the column I want to predict\n",
    "    - I will drop the `embark_town` column as it is redundant with the `embarked` column\n",
    "- I decided to drop the 2 rows having `NaN` values on the `embarked` column as we probably wont suffer a lot data loss and keep things \"real\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(labels=['deck', 'age', 'alive', 'embark_town', 'adult_male', 'pclass'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['survived']\n",
    "# Passing the \"cleaned\" DataFrame with exception of the 'survived' column\n",
    "X = df.drop('survived', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((666, 8), (223, 8), (666,), (223,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, random_state=42)\n",
    "Xtrain.shape, Xtest.shape, ytrain.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explore the data\n",
    "#### First I will assemble the train data together with its target to have a thorough exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>alone</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>woman</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>C</td>\n",
       "      <td>Third</td>\n",
       "      <td>child</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sex  sibsp  parch     fare embarked   class    who  alone  survived\n",
       "376  female      0      0   7.2500        S   Third  woman   True         1\n",
       "458  female      0      0  10.5000        S  Second  woman   True         1\n",
       "732    male      0      0   0.0000        S  Second    man   True         0\n",
       "507    male      0      0  26.5500        S   First    man   True         1\n",
       "830  female      1      0  14.4542        C   Third  child  False         1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulltraindf = pd.concat([Xtrain, ytrain], axis=1)\n",
    "fulltraindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(fulltraindf.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of my columns are not highly correlated which is good. This means, that I don't have a any reason to drop another column due to redundance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = fulltraindf['survived'].value_counts().plot(kind='bar', rot=0.5)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, that 408 people drowned, while 258 survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our columns and differiantiate between categorical columns and numerical ones\n",
    "\n",
    "Categorical:\n",
    "- In the `sex` column we have \"male\" and \"female\" as categories.\n",
    "- In the `embarked` column we have the ports in which the passengers boarded \"S\", \"C\" and \"Q\".\n",
    "- In the `class` column we have \"First\", \"Second\" and \"Third\" class as categories.\n",
    "- In the `who` column we have \"woman\", \"man\" and \"child\" as categories.\n",
    "- Finally in the `alone` column  we have \"True\" and \"False\" as values describing if the passengers were in compandy of another passenger or not\n",
    "\n",
    "Numerical:\n",
    "- We have the `sibsp` column describing the amount of siblings or spouses for each passenger. The numbers range between 0 and 8\n",
    "- The `parch` column describes how many parents/children the passenger has on board of the ship. These numbers range from 0 to 6\n",
    "- Finally we have the `fare` column describing how much the passenger paid for their ticket. Thes numbers range between 0 and 512.3292"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to hot-encode all the categorical columns and run the MinMaxScaler on all numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = ColumnTransformer(\n",
    "    (\n",
    "        ('cat_preprocessing', OneHotEncoder(sparse=False, handle_unknown='ignore'), ['sex', 'embarked', 'class', 'who', 'alone']),\n",
    "        ('num_preprocessing', MinMaxScaler(), ['sibsp', 'parch', 'fare'])\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "XtrainTrans = trans.fit_transform(Xtrain)\n",
    "XtestTrans = trans.transform(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Train Model\n",
    "#### 6.1 Have a baseline Model\n",
    "##### I decided to go with the DummyClassifier for the baseline modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = DummyClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.fit(XtrainTrans, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6126126126126126"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.score(XtrainTrans, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Train other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to run several models and use the VotingClassifier in order to select the one model with the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr = LogisticRegression()\n",
    "mrf = RandomForestClassifier()\n",
    "msv = SVC()\n",
    "tree = DecisionTreeClassifier(max_depth=3)\n",
    "models = [\n",
    "    ('logreg', mlr),\n",
    "    ('forest', mrf),\n",
    "    ('svm', msv),\n",
    "    ('tree', tree)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = VotingClassifier(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('logreg', LogisticRegression()),\n",
       "                             ('forest', RandomForestClassifier()),\n",
       "                             ('svm', SVC()),\n",
       "                             ('tree', DecisionTreeClassifier(max_depth=3))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(XtrainTrans, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8543543543543544, 0.8071748878923767)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy\n",
    "m.score(XtrainTrans, ytrain), m.score(XtestTrans, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy on the train data is 85% while on the test data it's lower - 80%. Let's proceed to optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will compare 4 performance metrics: `accuracy`, `precision`, `recall` and `f1`. I will create a DataFrame out of this `cross validation` in order to have a better overview of this metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = [\n",
    "    'accuracy',\n",
    "    'precision',\n",
    "    'recall',\n",
    "    'f1'\n",
    "]\n",
    "cols = ['traintest', 'model', 'metric', 'mean', 'std']\n",
    "traintest= [[XtrainTrans, ytrain], [XtestTrans, ytest]]\n",
    "metricdf = pd.DataFrame(columns=cols)\n",
    "for i in range(len(traintest)):\n",
    "    if i == 0:\n",
    "        trainortest = 'train'\n",
    "    else:\n",
    "        trainortest = 'test'\n",
    "    for model in models:\n",
    "        for metric in strings:\n",
    "            result = cross_val_score(model[1], traintest[i][0], traintest[i][1], cv = 10, scoring=metric)\n",
    "            row = {'traintest': trainortest, 'model': model[0], 'metric': metric, 'mean': round(np.mean(result), 3), 'std': round(np.std(result),5)}\n",
    "            metricdf = metricdf.append(row, ignore_index=True)\n",
    "    for metric in strings:\n",
    "        result = cross_val_score(m, traintest[i][0], traintest[i][1], cv = 10, scoring=metric)\n",
    "        row = {'traintest': trainortest, 'model': 'VotingClassifier', 'metric': metric, 'mean': round(np.mean(result), 3), 'std': round(np.std(result),5)}\n",
    "        metricdf = metricdf.append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>traintest</th>\n",
       "      <th>model</th>\n",
       "      <th>metric</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>logreg</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.03339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>logreg</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.05865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>logreg</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.07931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>logreg</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.04852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>forest</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.04102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>train</td>\n",
       "      <td>forest</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.09202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train</td>\n",
       "      <td>forest</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.06423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>train</td>\n",
       "      <td>forest</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>train</td>\n",
       "      <td>svm</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.02562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>train</td>\n",
       "      <td>svm</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.07042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>train</td>\n",
       "      <td>svm</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.08550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>train</td>\n",
       "      <td>svm</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.05303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>train</td>\n",
       "      <td>tree</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.03009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>train</td>\n",
       "      <td>tree</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.04929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>train</td>\n",
       "      <td>tree</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.06118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>train</td>\n",
       "      <td>tree</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.04271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>train</td>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.02402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>train</td>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.05324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>train</td>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.08959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>train</td>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.05068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>test</td>\n",
       "      <td>logreg</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.09079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>test</td>\n",
       "      <td>logreg</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.15184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>test</td>\n",
       "      <td>logreg</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.19462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>test</td>\n",
       "      <td>logreg</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.13741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>test</td>\n",
       "      <td>forest</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.06245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>test</td>\n",
       "      <td>forest</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.14019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>test</td>\n",
       "      <td>forest</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.12824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>test</td>\n",
       "      <td>forest</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.06677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>test</td>\n",
       "      <td>svm</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.07757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>test</td>\n",
       "      <td>svm</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.14795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>test</td>\n",
       "      <td>svm</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.18993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>test</td>\n",
       "      <td>svm</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.14818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>test</td>\n",
       "      <td>tree</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.08271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>test</td>\n",
       "      <td>tree</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.11654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>test</td>\n",
       "      <td>tree</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.21952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>test</td>\n",
       "      <td>tree</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.15760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>test</td>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.07037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>test</td>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.11946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>test</td>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.17906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>test</td>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.12151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   traintest             model     metric   mean      std\n",
       "0      train            logreg   accuracy  0.805  0.03339\n",
       "1      train            logreg  precision  0.770  0.05865\n",
       "2      train            logreg     recall  0.717  0.07931\n",
       "3      train            logreg         f1  0.739  0.04852\n",
       "4      train            forest   accuracy  0.821  0.04102\n",
       "5      train            forest  precision  0.792  0.09202\n",
       "6      train            forest     recall  0.748  0.06423\n",
       "7      train            forest         f1  0.760  0.04740\n",
       "8      train               svm   accuracy  0.815  0.02562\n",
       "9      train               svm  precision  0.876  0.07042\n",
       "10     train               svm     recall  0.620  0.08550\n",
       "11     train               svm         f1  0.719  0.05303\n",
       "12     train              tree   accuracy  0.824  0.03009\n",
       "13     train              tree  precision  0.800  0.04929\n",
       "14     train              tree     recall  0.732  0.06118\n",
       "15     train              tree         f1  0.763  0.04271\n",
       "16     train  VotingClassifier   accuracy  0.821  0.02402\n",
       "17     train  VotingClassifier  precision  0.851  0.05324\n",
       "18     train  VotingClassifier     recall  0.659  0.08959\n",
       "19     train  VotingClassifier         f1  0.736  0.05068\n",
       "20      test            logreg   accuracy  0.793  0.09079\n",
       "21      test            logreg  precision  0.761  0.15184\n",
       "22      test            logreg     recall  0.697  0.19462\n",
       "23      test            logreg         f1  0.705  0.13741\n",
       "24      test            forest   accuracy  0.780  0.06245\n",
       "25      test            forest  precision  0.715  0.14019\n",
       "26      test            forest     recall  0.646  0.12824\n",
       "27      test            forest         f1  0.670  0.06677\n",
       "28      test               svm   accuracy  0.798  0.07757\n",
       "29      test               svm  precision  0.828  0.14795\n",
       "30      test               svm     recall  0.597  0.18993\n",
       "31      test               svm         f1  0.671  0.14818\n",
       "32      test              tree   accuracy  0.785  0.08271\n",
       "33      test              tree  precision  0.756  0.11654\n",
       "34      test              tree     recall  0.635  0.21952\n",
       "35      test              tree         f1  0.667  0.15760\n",
       "36      test  VotingClassifier   accuracy  0.807  0.07037\n",
       "37      test  VotingClassifier  precision  0.818  0.11946\n",
       "38      test  VotingClassifier     recall  0.635  0.17906\n",
       "39      test  VotingClassifier         f1  0.697  0.12151"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metricdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some people prefer to use the `classification_report` function for this overview, so I took the opportunity to display the results with this function too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.85       408\n",
      "           1       0.77      0.73      0.75       258\n",
      "\n",
      "    accuracy                           0.81       666\n",
      "   macro avg       0.81      0.80      0.80       666\n",
      "weighted avg       0.81      0.81      0.81       666\n",
      "\n",
      "test LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.85       141\n",
      "           1       0.75      0.73      0.74        82\n",
      "\n",
      "    accuracy                           0.81       223\n",
      "   macro avg       0.80      0.79      0.80       223\n",
      "weighted avg       0.81      0.81      0.81       223\n",
      "\n",
      "train RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       408\n",
      "           1       0.94      0.90      0.92       258\n",
      "\n",
      "    accuracy                           0.94       666\n",
      "   macro avg       0.94      0.93      0.93       666\n",
      "weighted avg       0.94      0.94      0.94       666\n",
      "\n",
      "test RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       141\n",
      "           1       0.94      0.94      0.94        82\n",
      "\n",
      "    accuracy                           0.96       223\n",
      "   macro avg       0.95      0.95      0.95       223\n",
      "weighted avg       0.96      0.96      0.96       223\n",
      "\n",
      "train SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87       408\n",
      "           1       0.90      0.62      0.74       258\n",
      "\n",
      "    accuracy                           0.83       666\n",
      "   macro avg       0.85      0.79      0.80       666\n",
      "weighted avg       0.84      0.83      0.82       666\n",
      "\n",
      "test SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88       141\n",
      "           1       0.91      0.61      0.73        82\n",
      "\n",
      "    accuracy                           0.83       223\n",
      "   macro avg       0.86      0.79      0.81       223\n",
      "weighted avg       0.85      0.83      0.82       223\n",
      "\n",
      "train DecisionTreeClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87       408\n",
      "           1       0.83      0.74      0.78       258\n",
      "\n",
      "    accuracy                           0.84       666\n",
      "   macro avg       0.84      0.82      0.83       666\n",
      "weighted avg       0.84      0.84      0.84       666\n",
      "\n",
      "test DecisionTreeClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       141\n",
      "           1       0.87      0.66      0.75        82\n",
      "\n",
      "    accuracy                           0.84       223\n",
      "   macro avg       0.85      0.80      0.82       223\n",
      "weighted avg       0.84      0.84      0.83       223\n",
      "\n",
      "train VotingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89       408\n",
      "           1       0.90      0.71      0.79       258\n",
      "\n",
      "    accuracy                           0.85       666\n",
      "   macro avg       0.87      0.83      0.84       666\n",
      "weighted avg       0.86      0.85      0.85       666\n",
      "\n",
      "test VotingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.89       141\n",
      "           1       0.91      0.63      0.75        82\n",
      "\n",
      "    accuracy                           0.84       223\n",
      "   macro avg       0.87      0.80      0.82       223\n",
      "weighted avg       0.85      0.84      0.84       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "allmodels = [\n",
    "    mlr,\n",
    "    mrf,\n",
    "    msv,\n",
    "    tree,\n",
    "    m\n",
    "]\n",
    "for each in allmodels:\n",
    "    for dataset in range(len(traintest)):\n",
    "        if dataset == 0:\n",
    "            trainortest = 'train'\n",
    "        else:\n",
    "            trainortest = 'test'\n",
    "        each.fit(traintest[dataset][0], traintest[dataset][1])\n",
    "        pred = each.predict(traintest[dataset][0])\n",
    "        print(trainortest, str(type(each)).split('.')[-1].replace(\"'>\", \"\"))\n",
    "        print(classification_report(traintest[dataset][1], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the classification report vs. cross_val_score\n",
    "- With the cross_val_score it's easier to take a look at the model running with different sampling and several iterations.\n",
    "    - Using some statistical methods on the result helps me understand the level of robustness of each model\n",
    "        - It seems as if the level of robustness drops sigificantly with test/new data - This may be to the fact, that the test data set is smaller\n",
    "- Using the classification report helps me understand at which scoring method the models seem to perform better than other\n",
    "    - In train and test data the models seem to perform equally good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
